> Namespace

- 한 네임스페이스 안에서는 파드의 이름이 동일할 수 없다.
- 타 네임스페이스의 자원과 분리가 되어 관리된다.
- Pod 에 label을 달고, Service에 selector를 달아서 Pod-Service를 연결하곤 하는데, 이는 한 네임스페이스 안에서만 한정된 것이다.
- 네임스페이스를 지우게 되면 그 안에 있는 리소스들(파드, 서비스 등등)도 모두 지워지기 때문에 그걸 유의하자.
- 그런데 다른 네임스페이스에 있는 파드가 또 다른 네임스페이스에 연결할 수는 있을까? (-> 네트워크 폴리시로 가능하긴 함)

> ResourceQuota

- 네임스페이스에 자원을 제한하기 위한 것
- NameSpace 의 Request Memory, Limit Memory 를 지정함.
- 이걸 만들게 되면 파드를 생성할 때 스펙을 지정해야한다.
- 리소스쿼터를 만들때 할당할 네임스페이스를 지정하고, 자원과 한계치를 지정한다.
- 메모리 뿐만 아니라 CPU, Storage, 만들 수 있는 Object 의 숫자들도 지정할 수 있다. (Pod, Service, ConfigMap...)

> LimitRange

- 각각의 파드마다 네임스페이스에 들어올 수 있는 지 자원을 체크하기 위한 것이다.
- 파드에서 설정되는 Limit 의 설정값이, min, max, maxLimitRequestRatio 와 같은 한정을 짓는다.
- defaultRequest, default 값도 있는데 파드에 명시가 되지 않으면 파드 생성 요청 시 이 값으로 지정해준다는 것이다.

**네임스페이스 생성**

```
apiVersion: v1
kind: Namespace
metadata:
  name: dolphago-namespace
```

**파드 생성**

```
apiVersion: v1
kind: Pod
metadata:
  name: pod-1
  namespace: dolphago-namespace
  labels:
    app: pod
spec:
  containers:
  - name: container
    image: kubetm/app
    ports:
    - containerPort: 8080
```

**동일한 파드를 또 만드려고 하면**

![](/images/2024-08-06-16-45-23.png)

위와 같이 한 네임스페이스 내에서 파드는 유일해야함을 알 수 있다.

podIp: 20.96.36.97

**서비스 생성**

```
apiVersion: v1
kind: Service
metadata:
  name: svc-1
  namespace: dolphago-namespace
spec:
  selector:
    app: pod
  ports:
  - port: 9000
    targetPort: 8080
```

ServiceIp: 10.108.244.146


> ResourceQuata


```
apiVersion: v1
kind: Namespace
metadata:
  name: nm-3
```

```
apiVersion: v1
kind: ResourceQuota
metadata:
  name: rq-1
  namespace: nm-3
spec:
  hard:
    requests.memory: 1Gi
    limits.memory: 1Gi
```

![](/images/2024-08-06-16-56-06.png)

**파드 생성**

```
apiVersion: v1
kind: Pod
metadata:
  name: pod-2
spec:
  containers:
  - name: container
    image: kubetm/app
```

-> 실패: Why? 리소스 쿼터 명시 필요

![](/images/2024-08-06-16-56-57.png)

따라서 다음과 같이 파드를 생성해야함

```yml
apiVersion: v1
kind: Pod
metadata:
  name: pod-3
spec:
  containers:
  - name: container
    image: kubetm/app
    resources:
      requests:
        memory: 0.5Gi
      limits:
        memory: 0.5Gi
```

위 파드를 생성하면 남은 리소스가 0.5Gi 씩인데, 내가 만약 다음과 같이 추가 요청을 한다면 어떨까?

```yml
apiVersion: v1
kind: Pod
metadata:
  name: pod-4
spec:
  containers:
  - name: container
    image: kubetm/app
    resources:
      requests:
        memory: 0.7Gi
      limits:
        memory: 0.7Gi
```

![](/images/2024-08-06-16-58-13.png)

생성할 수 없다고 에러가 나게 된다.


그리고 만약에

파드를 미리 생성한다음에 나중에 리소스 쿼터를 만들면 어떻게 될까?

-> **그냥 잘 만들어진다.**

네임스페이스에 지정된 더 많은양의 자원을 쓸 수 있는 상황도 있을 수 있다.

따라서 리소스 쿼터를 만들기 전에 해당 네임스페이스에 다른 파드가 존재하지않도록 정리를 해주는 것이 중요하다.


> LimitRange

```yml
apiVersion: v1
kind: Namespace
metadata:
  name: nm-5
```

```yml
apiVersion: v1
kind: LimitRange
metadata:
  name: lr-1
spec:
  limits:
  - type: Container
    min:
      memory: 0.1Gi
    max:
      memory: 0.4Gi
    maxLimitRequestRatio:
      memory: 3
    defaultRequest:
      memory: 0.1Gi
    default:
      memory: 0.2Gi
```

> DaemonSet

- 데몬셋은 각 노드의 자원에 상관없이 생성 가능
- 데몬셋에 노드셀렉터를 지정해서 라벨링이 된 노드에만 설치하도록 구분은 시킬 수 있음
- 예를 들어 프로메테우스 같은 성능 관련, fluentd 와 같은 로깅 서비스, 노드들에 스토리치 설치
- 각각의 노드에 프록시 역할하는 파드를 설치함.
- hostPort 라는 옵션을 주면, 파드가 노드의 포트를 사용하는 것
  - containerPoint:8080, hostPort: 18080 이면, 노드 18080 -> (파드) -> 컨테이너 8080 으로 연결

