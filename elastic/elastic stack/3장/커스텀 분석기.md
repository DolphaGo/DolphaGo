# 커스텀 분석기

- 커스텀 분석기는 엘라스틱서치에서 제공하는 내장 분석기들 중 사용자가 원하는 기능을 만족할 수 없을 때 직접 토크나이저, 필터등을 조합해서 사용할 수 있는 분석기다.
- 필터들의 조합이나 순서에 따라 특별한 형태의 분석기를 만들 수 있다.


## 커스텀 분석기 설정
- customer_analyzer라는 인덱스를 하나 만들어보자.

```json
PUT customer_analyzer
{
  "settings": {
    "analysis": {
      "filter": {
        "my_stopwords":{
          "type": "stop",
          "stopwords": ["dolphago"]
        }
      },
      "analyzer": {
        "my_analyzer":{
          "type": "custom",
          "char_filter": [],
          "tokenizer": "standard",
          "filter": ["lowercase", "my_stopwords"]
        }
      }
    }
  }
}
```

- 인덱스 설정(settings)에 `analysis` 파라미터를 추가하고, 그 밑에 필터(`filter`)와 분석기(`analyzer`)를 만든다.
- 분석기(analyzer) 이름을 지정(my_analyzer)하고, **타입(type)을 `custom`으로 지정하면 커스텀 분석기**를 의미한다.
- **분석기엔 반드시 토크나이저가 하나 들어가야 하는데,** 여기선 기본(standard) 토크나이저를 사용했고, 캐릭터 필터(char_filter)는 사용하지 않았음.
- 토큰 필터로는 소문자 변경 필터와, 직접 만든 필터(my_stopwords)를 사용했다.
- 사용자가 만드는 필터는 analysis 파라미터 밑에 filter에서 이름을 지정(my_stopwords)하고, `타입(type)`과 타입에 맞는 설정을 작성하면 된다.
- 여기서는 기본 필터인 stop 필터에 사용자가 지정한 불용어를 추가했다.
  - `dolphago`라는 단어를 불용어로 인식하도록 설정해 `dolphago`라는 단어가 나오면 불용어로 처리한다.

> 위와 같이 인덱스를 만들었으니, 분석기 API를 통해 텍스트가 어떻게 토큰화 되는지 보자.

```json
GET customer_analyzer/_analyze
{
  "analyzer": "my_analyzer",
  "text": "What is your name? DolphaGo? dolphago? alphago?"
}
```
-> Response
```json
{
  "tokens" : [
    {
      "token" : "what",
      "start_offset" : 0,
      "end_offset" : 4,
      "type" : "<ALPHANUM>",
      "position" : 0
    },
    {
      "token" : "is",
      "start_offset" : 5,
      "end_offset" : 7,
      "type" : "<ALPHANUM>",
      "position" : 1
    },
    {
      "token" : "your",
      "start_offset" : 8,
      "end_offset" : 12,
      "type" : "<ALPHANUM>",
      "position" : 2
    },
    {
      "token" : "name",
      "start_offset" : 13,
      "end_offset" : 17,
      "type" : "<ALPHANUM>",
      "position" : 3
    },
    {
      "token" : "alphago",
      "start_offset" : 39,
      "end_offset" : 46,
      "type" : "<ALPHANUM>",
      "position" : 6
    }
  ]
}
```
- 우리가 방금 만들었던 custom_analyzer 라는 **인덱스** 안에 우리가 만들었던 my_anlyazer 분석기를 이용하여 테스트를 해본 것이다.

- 원래 standard 분석기였다면 `"What is your name? DolphaGo? dolphago? alphago?"` 라는 문장이 `What`, `is`, `your`, `name`, `DolphaGo`, `dolphago`, `alphago` 로 분리되었을 것이지만, 우린 여기에 lowercase 필터를 넣었기 때문에 모두 소문자로 변경되었을 것이다. 
- 위의 결과에 이어, **직접 만든 `my_stopwords`라는 필터**를 추가로 타게 되는데 이 필터의 역할은 사용자가 직접 커스텀한 stop 단어를 필터링한다.
- 여기서는 dolphago라는 단어를 stopwords로 넣었기 때문에 위와 같이 dolphago라는 단어는 사라지게 되는 것이다.
- 그래서 최종적으로 결과가 `what`, `is`, `your`, `name`, `alphago` 가 된다.
- 이 custom_analyzer 인덱스 외에 다른 인덱스에는 커스텀 분석기(my_analyzer)가 동작하지 않는데, 이는 커스텀 필터 또는 커스텀 분석기가 custom_analyzer 인덱스 내에 생성된 것이기 때문에 해당 인덱스 내에서만 유효하기 때문이다.

## 필터 적용 순서

