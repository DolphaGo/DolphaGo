- [파일 비트](#파일-비트)
  - [파일비트 아키텍처](#파일비트-아키텍처)
  - [파일비트 다운로드](#파일비트-다운로드)
  - [파일비트 실행](#파일비트-실행)
  - [파일비트 설정](#파일비트-설정)
    - [유용한 설정](#유용한-설정)
      - [ignore_older](#ignore_older)
      - [include_lines](#include_lines)
      - [exclude_lines](#exclude_lines)
      - [exclude_files](#exclude_files)
    - [멀티라인 로그처리](#멀티라인-로그처리)
  - [모듈](#모듈)
    - [비트다운로드](#비트다운로드)
    - [비츠 설정 파일 수정](#비츠-설정-파일-수정)
    - [모듈 활성화](#모듈-활성화)
    - [모듈 설정 파일 수정](#모듈-설정-파일-수정)
    - [setup 명령과 함께 비트 실행](#setup-명령과-함께-비트-실행)
    - [키바나에서 확인](#키바나에서-확인)
---

# 파일 비트
## 파일비트 아키텍처

- 서버나 시스템을 운영하다보면, 수많은 로그들이 파일 형태로 발생한다.
- 파일비트는 이런 로그 파일을 쉽게 수집하도록 도와주며 궁극적으로 엘라스틱과 키바나를 이용해 로그를 추적하고 통계를 만들어 활용할 수 있게 도와준다.
- 파일비트는 Go 언어로 작성되어있고, JVM 같은 무거운 런타임 라이브러리가 따로 필요하지 않아서 가볍기 때문에 수집할 시스템에 부담없이 설치될 수 있다.
- 로그스태시처럼 간단한 필터 작업도 가능하다.

> #### 파일비트 아키텍처 구조 
> [출처](https://www.elastic.co/guide/en/beats/filebeat/current/filebeat-overview.html)


![](/images/2022-04-19-00-05-29.png)

- 파일비트는 다음 3가지 주요 구성 요소로 이뤄져있다.

**1. 입력(input)**

- 설정 파일에서 하베스터에 대한 입력 소스를 정한다.
- 파일비트는 하나 혹은 여러 개의 입력을 가질 수 있다.

**2. 하베스터(harvester)**

- 입력에 명시된 파일을 직접 수집하는 주체다.
- 파일은 하나의 하베스터를 가지며, 하베스터는 파일을 한 줄씩 읽고 내보내는 역할을 한다.
- 또한 파일을 열고 닫는 역할도 한다.
- 하베스터가 실행되는 동안에는 파일 디스크립터가 열려있다.

**3. 스풀러(spooler)**

- 하베스터가 수집한 이벤트를 엘라스틱서치나 로그스태시 같은 장소로 전달한다.


파일비트는 기본적으로 파일에 적재되는 로그들을 가져오는 역할을 한다.
input에서 대상 경로를 모니터링하다가 새로운 파일이 발견되면, 하베스터를 생성해서 해당 데이터를 읽어들인다.



## 파일비트 다운로드

- [7.10.1 버전 다운로드](https://www.elastic.co/kr/downloads/past-releases/filebeat-7-10-1)

## 파일비트 실행

- 파일비트를 다운로드했으면, 이제 원하는 로그 파일을 수집하기 위해 설정 파일을 수정해야 한다.
- 파일비트를 폴더 내에 filebeat.yml 이라는 설정 파일이 있다.
- 설정 가능한 모든 파라미터는 [여기](https://www.elastic.co/guide/en/beats/filebeat/current/configuring-howto-filebeat.html)를 참고해보자.
  - 참고로, heartbeat나 metricbeat를 다운로드하면 heartbeat.yml이나 metricbeat.yml 이라는 이름의 설정 파일이 있고, 온라인 문서에서 설정 파일 사용법을 제공하고 있다.

- filebeat.yml을 다음과 같이 수정한다.

![](/images/2022-04-19-00-22-05.png)
![](/images/2022-04-19-00-23-10.png)
![](/images/2022-04-19-00-40-28.png)

- input은 파일비트가 가져오는 입력, output은 내보내는 출력이다.

> 파일비트 input 타입
- log
  - 가장 기본이 되는 타입으로, 파일시스템의 지정한 경로에서 로그 파일을 읽어 들인다.
- container
  - 도커 같은 컨테이너의 로그를 수집하기 위한 입력으로, 파일을 읽어 들인다는 점에서 log와 유사하다.
- s3
  - log 타입과 유사하나, 아마존 웹 서비스의 s3 버킷에 위치한 파일을 읽어들인다.
- kafka
  - 다른 타입과는 다르게 파일을 읽어들이는 대신 카프카의 토픽을 읽어들인다.


여기서는 input 타입을 log로 지정했는데, log타입은 paths에 지정된 파일의 로그를 한 줄씩 가져오는 것을 의미한다.

paths에 *.log를 가져오고 있기 때문에 logs 폴더에 있는 확장자가 log인 모든 파일을 가져온다.

아웃풋은 하베스터가 읽어들인 데이터를 전달할 곳으로, 엘라스틱서치, 로그스태시, 카프카, 특정 파일, 콘솔 등 여러 형태의 아웃풋 중 하나를 선택할 수 있다.

> 파일비트 output 타입

- elasticsearch
  - 가장 많이 사용되는 타입으로, 수집한 이벤트를 엘라스틱서치로 직접 인덱싱한다.

- logstash
  - 다수의 비츠를 사용해 엘라스틱서치로 전송되는 인덱싱 리퀘스트의 양이 많거나, 비츠나 인제스트 노드 수준에서 처리하기 어려운 가공 작업이 필요할 때 별도의 로그스태시를 구축한 후, 수집한 이벤트를 전송한다. 다수의 인덱싱 요청이 로그스태시에서 단일 벌크 리퀘스트로 묶여 인덱싱 효율의 개선을 기대할 수 있다.
  - 이때 전송한 이벤트는 로그스태시의 beats input을 이용해 입력받을 수 있다.

- kafka
  - 파일비트에서 1차적으로 수집한 이벤트를 카프카로 전송한다.
  - 카프카는 좀 더 안정적인 수집 파이프라인을 구성할 때 신뢰할만한 중간 저장소/큐이므로 수집 중 장애 발생 시 데이터 손실을 최소화하기 위한 방안으로 활용된다.
  - 최종적으로 엘라스틱서치의 인덱싱을 원할 경우 이후 다시 파일비트의 카프카 인풋을 이용하거나, 로그스태시의 카프카 인풋을 이용해 입력할 수 있다.

- console
  - 수집한 이벤트를 시스템 콘솔에 출력한다.
  - 일반적으로 수집이 정상적으로 이뤄지는지 입력 설정을 테스트하기 위한 목적으로 사용된다.

우리가 예제로 설정한 것처럼, elasticsearch를 아웃풋으로 지정하면, 반드시 엘라스틱서치 호스트 주소(hosts)를 적어야 한다.

마지막으로, `setup.kibana`를 지정하면 키바나 대시보드에서 파일비트 데이터를 확인할 수 있다.

이제 파일 비트를 실행해보자.
```sh
./filebeat setup -e
```

- 파일비트를 실행하기 전에 setup 옵션을 실행한다. `-e`는 모니터에 오류나 로그를 보여주는 옵션이다.
- 혹시나 실행이 안된다면, [여기](https://github.com/DolphaGo/DolphaGo/issues/97)를 참고해보자. 스토리지 문제일 수 있다.
- 정상적으로 실행이 되었다면 다음과 같은 로그를 확인할 수 있다.

```
Loading dashboards (Kibana must be running and reachable)
2022-04-19T03:06:26.232+0900	INFO	kibana/client.go:119	Kibana url: http://localhost:5601
2022-04-19T03:06:27.342+0900	INFO	kibana/client.go:119	Kibana url: http://localhost:5601
2022-04-19T03:07:36.511+0900	INFO	instance/beat.go:815	Kibana dashboards successfully loaded.
Loaded dashboards
2022-04-19T03:07:36.511+0900	WARN	[cfgwarn]	instance/beat.go:556	DEPRECATED: Setting up ML using Filebeat is going to be removed. Please use the ML app to setup jobs. Will be removed in version: 8.0.0
Setting up ML using setup --machine-learning is going to be removed in 8.0.0. Please use the ML app instead.
See more: https://www.elastic.co/guide/en/machine-learning/current/index.html
2022-04-19T03:07:36.511+0900	INFO	eslegclient/connection.go:99	elasticsearch url: http://localhost:9200
2022-04-19T03:07:36.513+0900	INFO	[esclientleg]	eslegclient/connection.go:314	Attempting to connect to Elasticsearch version 7.10.2
2022-04-19T03:07:36.513+0900	INFO	kibana/client.go:119	Kibana url: http://localhost:5601
2022-04-19T03:07:36.528+0900	WARN	fileset/modules.go:421	X-Pack Machine Learning is not enabled
Loaded machine learning job configurations
2022-04-19T03:07:36.529+0900	INFO	eslegclient/connection.go:99	elasticsearch url: http://localhost:9200
2022-04-19T03:07:36.531+0900	INFO	[esclientleg]	eslegclient/connection.go:314	Attempting to connect to Elasticsearch version 7.10.2
2022-04-19T03:07:36.531+0900	INFO	cfgfile/reload.go:262	Loading of config files completed.
Loaded Ingest pipelines
```

- 엘라스틱서치 인덱스 템플릿, 수명주기 정책과 같은 인덱스 관리 정보와 인제스트 파이프라인, 그리고 키바나 샘플 대시보드까지 설치하기 때문에 셋업하는데 시간이 조금 걸릴 것이다.
- 실행이 완료되었다면, 키바나의 **대시보드**에 `filebeat-*`의 인덱스들이 생성이 되고 관련된 샘플 대시보드들이 추가된다.
![](/images/2022-04-19-03-07-59.png)

- 파일비트와 엘라스틱서치, 키바나 간의 셋업이 끝나면 이제 마지막으로 파일 비트를 실행해보자

```sh
./filebeat -e
```

- `-e` 옵션은 오류나 로그를 확인하기 위함이다.
- 키바나 > Management > Stack Management > Index Management 로 이동한다.

![](/images/2022-04-19-03-10-16.png)
- 현재 클러스터의 인덱스들을 확인할 수 있는데, `filebeat-*` 라는 이름의 인덱스가 보일 것이다.
- 우리가 직접 만들진 않았찌만, 파일비트에서 setup 과정을 통해 만들어졌다.

또한 로그를 직접 확인해볼 수 있다. Kibana > Discover로 가보자.
![](/images/2022-04-19-03-16-40.png)


## 파일비트 설정

- 파일비트를 설치한 폴더를 보면 `filebeat.reference.yml`이라는 파일이 있다.
- 파일비트의 모든 설정에 대한 설명과 기본값이 적혀있는 참조 파일이다.
- 버전에 맞춰 추가/삭제된 옵션이 모두 포함되어있으니, 설정파일을 수정할 때 참고하자.

### 유용한 설정

#### ignore_older

- `ignore_older` 는 새로운 파일 탐색 시 오래된 파일을 읽어들이지 않고 무시하기 위한 설정이다.
```yml
...
  #------------------------------ Log input --------------------------------
  - type: log
    enabled: true
    paths:
      - /Users/user/dev/elasticsearch-7.10.2/logs/*.log
    ignore_older: 24h
...
```
- ignore_older는 인풋 타입이 log인 경우 사용할 수 있는 옵션으로, ignore_older 값은 10h(10시간), 10m(10분) 처럼 타임스트링 형식으로 작성한다.
  - 예를 들어, ignore_older를 10h로 설정하면 최근 10시간 전의 로그만 수집하겠다는 의미이다.
- ignore_older의 기본값은 0으로, 특별히 값을 명시하지 않으면, 파일의 생성/수정 시간과 무관하게 모든 내용을 읽어들인다.


```yml
filebeat.inputs:
  - type: log
    enabled: true
    paths:
      - /Users/user/dev/elasticsearch-7.10.2/logs/*.log
    exclude_lines: ['^DBG']
    include_lines: ['^ERR', '^WARN']
    exclude_files: ['.gz$']

    ...
```

#### include_lines

- 특정 라인이나 파일을 추가/제외하는 옵션
- 특정 라인을 정규식을 이용해 필터링하고 매칭된 라인만 비츠에서 수집한다.
  - 파일비트 수준에서 복잡한 정제 작업을 수행할 수는 없지만, 간단한 정제 작업을 비츠에서 처리하면 엘라스틱 서치나 로그스태시에서 처리하는 작업량을 줄일 수 있다.
- 여기에서 ERR이나 WARN으로 시작하는 로그 라인은 파일비트가 수집한다.
  
#### exclude_lines

- 특정 라인을 정규식 표현식을 이용해 필터링하고, 매칭된 라인은 비츠에서 수집하지 않는다.
- 여기서 DBG로 시작하는 로그 라인은 파일비트 내부에서 버린다.

#### exclude_files

- 패턴에 일치하는 파일을 무시할 때 사용한다.
- 여기에서 확장자가 gz인 파일은 무시한다.
- 특정 폴더 내부에 분석해야 하는 로그 파일과 분석하지 않아도 되는 파일들이 섞여 있을 때 유용하게 사용할 수 있다.


### 멀티라인 로그처리

- 로그가 한 줄로 표현되면 좋겠지만, 하나의 로그가 여러줄로 나올 때는 어떻게 처리해야 할까? (~~ at 어쩌구 저쩌구 \n at 어쩌구 저쩌구...)
- 자바 프로그램에서 자주 보이는 로그패턴으로, 여러 라인을 하나의 로그로 인식해야 한다.
- 파일비트는 이런 경우를 위해 멀티라인 옵션을 제공하고 있다.
- 자바 오류는 스택 트레이스 정보를 담고 있기 때문에 실제로 하나의 오류를 멀티라인으로 표현한다.
- 멀티라인을 하나의 라인처럼 처리하는 방법을 `코덱`에서 잠깐 다뤘는데, 용어만 조금 다를 뿐 사용법은 비슷하다.
- 멀티라인을 처리하기 위한 설정 방법을 알아보자

```yml
    # The regexp Pattern that has to be matched. The example pattern matches all lines starting with [
    multiline.pattern: '^[[:space:]]'

    # Defines if the pattern set under pattern should be negated or not. Default is false.
    multiline.negate: false

    # Match can be set to "after" or "before". It is used to define if lines should be append to a pattern
    # that was (not) matched before or after or as long as a pattern is not matched based on negate.
    # Note: After is the equivalent to previous and before is the equivalent to to next in Logstash
    multiline.match: after
```

- input 타입이 log인 경우에 멀티라인을 처리할 수 있다.
- 일반적으로 로그는 한 줄에 하나의 로그가 기록되며, 파일비트 또한 싱글라인 단위로 이벤트를 처리한다.
- 하지만, 경우에 따라 하나의 로그가 어려 줄에 걸쳐 기록되는 경우가 있는데, 이때 `multiline` 설정을 이용할 수 있다.
- `multiline` 설정에는 pattern, negate, match라는 세가지 하위 옵션이 있으며, 이 세 가지 설정을 조합해 읽어들인 줄이 로그의 끝인지, 아니면 다음 줄을 계속해서 읽어 들일지 결정할 수 있다.


- `multiline.pattern` 은 정규식을 이용해 패턴을 지정한다.
  - 패턴과 일치하는 라인이 나타나면 멀티라인으로 인식한다.
  - 위의 예시에서는 첫 번째 문자가 공백이면 멀티라인 패턴으로 인식한다.
  - 자바 오류 로그들에 대해서는 모두 멀티라인 패턴에 해당된다.
- `multiline.negate`는 true일 때 패턴 일치 조건을 반전시킨다.
  - 만약 위의 예시에서 true로 변경했다면, 첫 번째 문자가 공백이 아닐 때 멀티라인으로 인식한다.
- `multiline.match`는 멀티라인을 처리하는 방식으로 `before`, `after`를 지정할 수 있다.
  - 위의 예시로는 매칭 패턴에 일치하는 공백으로 시작하는 라인을 공백으로 시작하지 않는 **라인 뒤에 붙이는** 방식으로 멀티라인 자바 로그를 하나의 로그로 처리할 수 있다.
  

> 멀티라인 이해

- 멀티라인 로그가 다음과 같이 있다고 생각해보자

```
aoo
koo
boo
boo
zoo
boo
```

- 위와 같이 여섯 라인으로 되어 있는 멀티라인 로그가 있다고 할 때 파일비트를 이용해 멀티라인 처리를 해보자
- 나는 `/Users/user/dev/filebeat-7.10.1-darwin-x86_64/sample-data` 경로에 `test.log`라는 이름으로 위의 데이터를 만들어놨다.
- 그리고 filebeat.yml은 다음과 같이 세팅했다.

> 예제 1

```yml
filebeat.inputs:
- type: log
  enabled: true
  paths:
    - /Users/user/dev/filebeat-7.10.1-darwin-x86_64/sample-data/test.log
  exclude_lines: ['^DBG']
  include_lines: ['^ERR', '^WARN']
  exclude_files: ['.gz$']
  ignore_older: 24h
  multiline.pattern: '^b'
  multiline.negate: false
  multiline.match: after
...

output.console:
  enabled: true
  pretty: true
```

그리고 파일비츠를 실행해보면
```
2022-04-19T05:22:34.304+0900	INFO	log/harvester.go:302	Harvester started for file: /Users/user/dev/filebeat-7.10.1-darwin-x86_64/sample-data/test.log
2022-04-19T05:22:54.193+0900	INFO	[monitoring]	log/log.go:145	Non-zero metrics in the last 30s	{"monitoring": {"metrics": {"beat":{"cpu":{"system":{"ticks":57,"time":{"ms":6}},"total":{"ticks":237,"time":{"ms":13},"value":237},"user":{"ticks":180,"time":{"ms":7}}},"info":{"ephemeral_id":"eaab15f7-6ff4-46f6-b4e9-ef526194a28b","uptime":{"ms":90064}},"memstats":{"gc_next":18017536,"memory_alloc":12614160,"memory_total":71531112,"rss":49152},"runtime":{"goroutines":45}},"filebeat":{"events":{"added":6,"done":6},"harvester":{"open_files":3,"running":3,"started":2}},"libbeat":{"config":{"module":{"running":0}},"pipeline":{"clients":1,"events":{"active":0,"filtered":6,"total":6}}},"registrar":{"states":{"current":8,"update":6},"writes":{"success":6,"total":6}},"system":{"load":{"1":2.3994,"15":2.5957,"5":2.4888,"norm":{"1":0.2,"15":0.2163,"5":0.2074}}}}}}
```

- 하베스트가 내가 지정한 파일에서 데이터를 수집하기 시작했고, added 6, done 6 등을 보면 이벤트가 제대로 수집되고 있음을 확인할 수 있다.


- 앞서 이야기한 내용이지만, 위 설정을 해석해보면 다음과 같다.
- 라인의 첫 번째 문자가 `b`로 시작할 경우, 패턴으로 인식한다.
- negate가 false이니 패턴이 일치하는 연속된 라인을
- match가 after이니 패턴이 일치하지 않는 앞쪽 라인에 붙인다는 의미이다.
- 즉, 로그
aoo
koo
boo
boo
zoo
boo를 읽을 때 boo는 패턴에 걸리게 되는데, 이 때 그 전인 koo에 붙어서 `koo boo boo`가 하나의 로그로 인식되고, 그 다음 줄인 `zoo boo`가 하나의 로그로 인식되는 것이다.
- 여기서 `aoo`의 경우 패턴에 맞지 않고, 뒤에도 패턴에 맞는 라인이 없어서 무시 된다.
- 최종적으로 `koo boo boo`, `zoo boo` 가 되는 것이다.


> 예제 2
```
aoo
koo
boo
boo
zoo
boo
```
```yml
multiline.pattern: '^b'
multiline.negate: false // 패턴이 일치하는 연속된 라인을
multiline.match: before // 패턴이 일치하지 않는 뒤쪽 라인에 붙인다.
```

- 다시 순서대로 파악해보자.
- 첫 번째 라인 aoo, 두 번째 라인 koo는 패턴에 맞지 않고, 앞쪽에도 패턴에 맞는 라인이 없다 => 무시 된다.
- `boo boo` 는 패턴에 맞는 연속된 라인으로, 다음 라인에 나오는 패턴과 맞지 않는 `zoo` 와 결합해서 `boo boo zoo`가 된다.
- 마지막 `boo`는 다음 라인이 없지만, 패턴에 맞기 때문에 혼자 멀티라인을 구성한다.
- 최종적으로 `boo boo zoo`, `boo`라는 2개의 로그가 생성된다.

> 예제 3
```
aoo
koo
boo
boo
zoo
boo
```

```yml
multiline.pattern: '^b'
multiline.negate: true // 패턴이 일치하지 않는 연속된 라인을
multiline.match: after // 패턴이 일치하는 앞쪽 라인에 붙인다.
```

- b로 시작하지 않는 aoo koo와 zoo가 패턴에 일치하지 않는 것에 속한다.
- match는 after로 되어있다. after는 기준 라인(패턴이 일치하지 않는 연속된 라인)이 패턴이 일치하는 라인 앞쪽에 붙는다.
- 즉 패턴에 맞지 않는 연속된 라인들이 있고, 그 앞 라인이 패턴에 맞을 경우 멀티라인을 구성한다.
*(before, after 반대로 느껴져서 살짝 어지럽네;)*
- `aoo koo`는 패턴에 맞지 않는 연속된 라인이나, 앞에 라인이 없어서 무시된다.
- `boo` 는 패턴에 맞기 때문에 홀로 멀티라인을 구성한다.
- `zoo 는 앞라인에 패턴에 맞는 라인이 있어서 `boo zoo`로 멀티라인을 구성한다.
- 마지막 `boo` 역시 홀로 멀티라인을 구성한다.
- 이 경우 최종적으로 `boo`, `boo zoo`, `boo` 3개의 로그를 만든다.

> 예제 4

```text
aoo
koo
boo
boo
zoo
boo
```

```yml
multiline.pattern: '^b'
multiline.negate: true // 패턴이 일치하지 않는 연속된 라인을
multiline.match: before // 패턴이 일치하는 뒤쪽 라인에 붙인다.
```

- `aoo koo`는 패턴에 맞지 않는 연속된 라인인데 뒤 라인에 패턴에 맞는 `boo` 가 와서 결합하고, `aoo koo boo`라는 멀티라인이 구성된다.
- 네번째 `boo`는 해당사항은 없지만 패턴에 맞기에 홀로 멀티라인을 구성한다.
- `zoo`는 다음 `boo`와 결합해 `zoo boo` 멀티라인을 구성한다.
- 최종적으로 `aoo koo boo`, `boo`, `zoo boo` 가 된다.


## 모듈
- 모듈은 많이 사용되고 잘 알려진 시스템 데이터를 수집하기 위한 일반적인 설정을 사전 정의해둔 것
- 모듈을 이용하면 복잡한 가공이 필요한 이벤트인 경우에도 최소한의 비츠 설정으로 손쉽게 로그들을 수집할 수 있다.
- 모듈의 핵심은 손 쉬운 사용
- 예를 들어 엔진엑스/아파치 서버의 로그를 수집할 때 특별히 사용자 변경이 없었다면 설치 경로나 발생위치, 로그 형태는 동일할 것이다.
- 이렇게 well-known 서비스들은 동일한 설정으로 수집할 수 있기 때문에 모듈이라는 형태로 사전 설정을 제공하고 있다.
- 따라서 비츠를 이용해 로그를 수집할 계획이 있다면 먼저 적합한 모듈이 있는지 찾아보자.
- 비츠가 모듈을 지원하는지 여부를 확인하는 다양한 방법이 있지만 온라인 문서 확인이 가장 좋다.

> 자주 사용하는 파일비트 모듈

- aws
  - AWS의 CloudWatch, CloudTrail 같은 서비스에서 발생하는 로그들을 수집할 수 있다.
- cef
  - 시스로그를 통해 CEF(Common Event Format) 이벤트를 입력받을 수 있다.
- cisco
  - 시스코사의 ASA, Nexus 등 네트워크 장비에서 발생되는 이벤트를 수집한다.
- elasticsearch
  - 엘라스틱서치의 클러스터, GC, 감사로그 등을 수집할 때 사용한다.
- googlecloud
  - 구글 클라우드 플랫폼의 VPC 플로우, 방화벽 로그 등을 수집할 수 있다.
- logstash
  - 로그스태시에서 발생한 로그들을 수집할 수 있다.

> 모듈을 이용한 비트 동작 과정

1. 비트를 다운로드한다.
2. 비트 설정 파일을 수정한다.
3. 모듈을 활성화하고 모듈 설정 파일을 수정한다.
4. 엘라스틱서치와 키바나 대시보드를 사용할 수 있게 설정한다.
5. 비트를 시작한다.
6. 키바나 대시보드에서 데이터를 확인한다.

### 비트다운로드

- [7.10](https://www.elastic.co/guide/en/beats/filebeat/7.10/filebeat-modules.html)
- 여기서 [logstash 모듈](https://www.elastic.co/guide/en/beats/filebeat/7.10/filebeat-module-logstash.html)을 사용해보자.

### 비츠 설정 파일 수정

- 모듈 사용을 위해 먼저 비츠 설정 파일을 변경해줘야 한다.
- 인풋은 모듈 설정 파일에서 설정할 것이므로, 아웃풋만 적어주자.
- filebeat.yml을 다음과 같이 수정하자.

```yml
# ---------------------------- Elasticsearch Output ----------------------------
output.elasticsearch:
  # Array of hosts to connect to.
  hosts: ["localhost:9200"]

setup.kibana:
  host: "localhost:5601"

filebeat.config.modules:
  path: ${path.config}/modules.d/*.yml
```

- 인풋은 모듈 설정 파일에서 작성해야 하므로 삭제한다(enable false 처리)
- 아웃풋은 엘라스틱서치로 설정했고, setup.kibana를 추가해 키바나에 샘플 대시보드를 설치할 수 있도록 지정했다.
- 마지막으로 모듈을 설정하기 위해서는 모듈 경로를 지정해줘야 한다.
- `${path.config}` 는 파일비트가 설치된 경로이다.

### 모듈 활성화

이제 콘솔에서 모듈을 활성화해보자

```sh
➜ ./filebeat modules enable logstash
Enabled logstash
```
- 파일 비트를 실행하고 modules 명령을 적어준다.
- 다음으로 enable/disable 을 이용해 모듈을 활성화하거나 비활성화 할 수 있다.
- 마지막으로 모듈 이름을 적어주면 된다. 여러개 가능하다. 모듈명 사이에 공백을 두면 된다.
- 현재 활성화된 모듈이 무엇인지 확인하는 방법도 알아보자.

```sh
./filebeat modules list

Enabled:
logstash

Disabled:
activemq
apache
auditd
aws
azure
barracuda
bluecoat
...
```

### 모듈 설정 파일 수정

- 이제 모듈 속성 파일(logstash.yml)을 수정해본다.
- 모듈 설정 파일은 파일비트 디렉토리 아래에 modules.d 디렉토리에 있다.
- 비활성화된 모듈들은 disabled 확장자가 붙고, 활성화된 모듈은 disabled 확장자가 빠진다.
- logstash 모듈은 일반 로그와 슬로우 로그 수집을 지원한다.
- 로그스태시 실행 중 발생된 대부분의 로그는 일반 로그에 속하고, 파이프라인 내에서 과도하게 처리 시간이 지연되는 이벤트의 경우 별도의 파일에 슬로우 로그로 기록된다.
- 테스트 차원에서 일반 로그만 경로를 지정한다.
- `var.paths` 에 로그스태시 로그 경로를 지정해주는데, 경로를 지정하지 않으면 파일 비트가 운영체제에 맞는 경로를 자동으로 지정한다.

```sh
cat logstash.yml
# Module: logstash
# Docs: https://www.elastic.co/guide/en/beats/filebeat/7.10/filebeat-module-logstash.html

- module: logstash
  # logs
  log:
    enabled: true

    # Set custom paths for the log files. If left empty,
    # Filebeat will choose the paths depending on your OS.
    var.paths:
       - /Users/user/dev/logstash-7.10.2/logs/logstash-plain.log

  # Slow logs
  slowlog:
    enabled: true
    # Set custom paths for the log files. If left empty,
    # Filebeat will choose the paths depending on your OS.
    #var.paths:
```


### setup 명령과 함께 비트 실행

- 비트 설정과 모듈 설정까지 완료했으므로 비트를 실행할 것이다.
- 먼저 setup 명령을 통해 엘라스틱 인덱스 템플릿을 생성하고 키바나 대시보드를 사용할 수 있게 한다.

```sh
./filebeat setup
```

- setup 명령은 엘라스틱서치와 키바나에 API를 이용해 인제스트 파이프라인, 대시보드 등을 설치하므로 엘라스틱서치와 키바나는 반드시 실행 중이어야 하며, 네트워크 접근에도 문제가 없어야 한다.

- `키바나 > 대시보드 > [Filebeat Logstash] Logstash Logs ECS` 에서 대시보드를 확인해보자 .
- 아직 파일비트 시작 전이라 데이터가 수집되지 않아 대시보드에 아무것도 보이지 않는다.
- 이제 파일비트를 실행시켜본다.

```sh
./filebeat -e
```

- `-e`옵션이 있으므로 로그들이 보일텐데 특별한 에러로그가 없으면 잘 실행된거다.
- 만약 오류가 있으면 `-d '*'` 옵션으로 디버깅 메세지도 볼 수 있다.

```
./filebeat -e -d "*"
```

- 파일비트가 로그스태시 모듈에서 파일을 가져오기 위해서는 로그스태시를 실행해야 한다.(6장까지 따라해봤다면 파이프라인 2개가 실행되면서 로그스태시가 동작할 것이다.)
- 로그스태시가 실행되고 로그파일(logstash-plain.log)에 파일이 쌓이면 파일비트의 로그스태시 모듈이 이를 감지한다.

```
Harvester started for file: /Users/user/dev/logstash-7.10.2/logs/logstash-plain.log
```

### 키바나에서 확인

- 이제 다시 대시보드를 확인해보면 방금 로그스태시를 실행하고 비츠가 로그를 수집하자 비츠를 실행하기 전엔 비어있던 대시보드에 데이터가 추가됐음을 알 수 있다.

![](/images/2022-04-28-08-13-21.png)