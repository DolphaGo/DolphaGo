- [Metric aggregation](#metric-aggregation)
    - [평균값/중간값 구하기](#평균값중간값-구하기)
    - [필드의 유니크한 값 개수 확인하기](#필드의-유니크한-값-개수-확인하기)
    - [검색 결과 내에서의 집계](#검색-결과-내에서의-집계)

# Metric aggregation

- 필드의 **최소/최대/합계/평균/중간값**같은 통계 결과를 보여줌
- 필드의 타입에 따라서 사용 가능한 집계 타입에 제한이 있음
  - 대표적으로 텍스트 타입 필드는 합계나 평균 같은 수치 연산을 할 수 없음


> 메트릭 집계 종류

| 메트릭 집계  | 설명                                                                  |
| ------------ | --------------------------------------------------------------------- |
| avg          | 필드의 평균값 계산                                                    |
| min          | 필드의 최솟값 계산                                                    |
| max          | 필드의 최댓값 계산                                                    |
| sum          | 필드의 총합을 계산                                                    |
| percentiles  | 필드의 백분윗값을 계산                                                |
| stats        | 필드의 min, max, sum, avg, count(도큐먼트 개수)를 한 번에 볼 수 있다. |
| cardinality  | 필드의 유니크한 값 개수를 보여준다.                                   |
| geo-centroid | 필드 내부의 위치 정보의 중심점을 계산한다.                            |

### 평균값/중간값 구하기

- 평균값을 구할 수 있는 평균 집계(avg aggregation)
- 중간값을 구할 수 있는 백분위 집계(percentiles aggregation)


> 평균값을 구하는 집계 요청

```json
GET kibana_sample_data_ecommerce/_search
{
  "size": 0,
  "aggs": {
    "stats_aggs": {
      "avg": {
        "field": "products.base_price"
      }
    }
  }
}
```
-> Response
```json
{
  "took" : 448,
  "timed_out" : false,
  "_shards" : {
    "total" : 1,
    "successful" : 1,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : {
      "value" : 4675,
      "relation" : "eq"
    },
    "max_score" : null,
    "hits" : [ ]
  },
  "aggregations" : {
    "stats_aggs" : {
      "value" : 34.88652318578368
    }
  }
}
````

- 평균 집계(avg)를 이용해 products.base_price 필드의 평균값을 구하는 요청이다.
- 집계 이름 : stats_aggs
- 집계 타입 : avg
- **평균 집계를 사용하기 위해서는 필드 타입이 정수나 실수 타입이어야 한다.**
- 평균값을 구하고 싶은 필드명 : products.base_price
- `"size" : 0` : 집계에 사용한 도큐먼트를 결과에 포함하지 않음 -> 비용 절감 가능
- 평균 가격이 34.8865... 인 것을 알 수 있다.


> 백분위를 구하는 집계 요청

```json
GET kibana_sample_data_ecommerce/_search
{
  "size": 0,
  "aggs": {
    "stats_aggs": {
      "percentiles": {
        "field": "products.base_price",
        "percents": [
          25,
          50
        ]
        
      }
    }
  }
}
```
-> Response
```json
{
  "took" : 107,
  "timed_out" : false,
  "_shards" : {
    "total" : 1,
    "successful" : 1,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : {
      "value" : 4675,
      "relation" : "eq"
    },
    "max_score" : null,
    "hits" : [ ]
  },
  "aggregations" : {
    "stats_aggs" : {
      "values" : {
        "25.0" : 16.984375,
        "50.0" : 25.656941371681416
      }
    }
  }
}
```
- 집계 타입 : percentiles (백분위 집계)
- **백분위 집계는 필드의 특정 백분위에 속하는 데이터를 찾아줌**
  - 그러니, 중간값은 50, 최댓값은 100이라고 볼 수 있다.
  - 예를 들어 percents를 100으로 지정하면, 최댓값인 max와 동일하다.
- 우리는 25%, 50%에 속하는 데이터를 요청한다.


### 필드의 유니크한 값 개수 확인하기

- 카디널리티 집계 : 필드의 중복된 값들은 제외하고 유니크한 데이터의 개수만 보여준다.
- SQL의 distinct count라고 이해하면 된다.

```json
GET kibana_sample_data_ecommerce/_search
{
  "size": 0,
  "aggs": {
    "cardi_aggs": {
      "cardinality": {
        "field": "day_of_week",
        "precision_threshold": 100
      }
    }
  }
}
```
-> Response
```json
{
  "took" : 221,
  "timed_out" : false,
  "_shards" : {
    "total" : 1,
    "successful" : 1,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : {
      "value" : 4675,
      "relation" : "eq"
    },
    "max_score" : null,
    "hits" : [ ]
  },
  "aggregations" : {
    "cardi_aggs" : {
      "value" : 7
    }
  }
}
```
- 여기서 `precision_threshold` 파라미터는 정확도 수치라고 이해하자.
  - 값이 크면, 정확도가 올라가는 대신 시스템 리소스를 많이 소모한다.
  - 값이 작으면, 정확도는 떨어지는 대신 시스템 리소스를 덜 소모한다.
- aggregations 아래 value 값인 7은 요일의 개수를 의미한다.
- 카디널리티는 매우 적은 메모리로 집합의 원소 개수를 추정할 수 있는 **HyperLogLog++ 알고리즘** 기반으로 동작하며, `precision_threshold` 파라미터를 이용해 정확도와 리소스를 등가교환한다.
- 그래서 내가 만약 정확도를 5라고 주면 다음과 같은 결과가 나타난다.
```json
GET kibana_sample_data_ecommerce/_search
{
  "size": 0,
  "aggs": {
    "cardi_aggs": {
      "cardinality": {
        "field": "day_of_week",
        "precision_threshold": 5
      }
    }
  }
}
```
-> Response
 ![](/images/2022-04-11-23-16-24.png)

 - 그림에서 볼 수 있듯 잘못된 결과 8을 알려준다.
 - 일반적으로 `precision_threshold` 값은 카디널리티의 실제 결과(7)보다 크게 잡아야 한다.
   - 하지만 실제 결과를 모르기에 precision_threshold 값을 변경해보면서 값이 변경되지 않는 임계점을 찾는 것도 방법이다.
 - `precision_threshold` 기본값은 3000, 최대 40000까지 값을 설정할 수 있다.

> HyperLogLog++ 알고리즘

- 집합 내 중복되지 않는 항목의 개수를 세기 위한 알고리즘
- 완전히 정확한 값을 반환하지는 않으나, 일반적으로 5%이내의 오차
- 정밀도를 직접 지정해 오차율을 낮출 수 있다는 점
- 카디널리티가 낮은(중복을 제거한 항목수가 적은) 집합일수록 100%의 정확성을 보임.
- 집계 대상의 크기가 얼마나 크든 간에 지정한 정밀도 이상의 메모리를 사용하지 않기에 **엘라스틱서치와 같이 대용량 데이터베이스에서 유용한 알고리즘**임.


<br/>

이번에는 **유니크한 필드값**을 알아보자.

> 용어 집계 요청
```json
GET kibana_sample_data_ecommerce/_search
{
  "size": 0,
  "aggs": {
    "cardi_aggs": {
      "terms": {
        "field": "day_of_week"
      }
    }
  }
}
```
-> Response
![](/images/2022-04-11-23-20-45.png)
- 위 요청은 버킷 집계 중 용어 집계로, `day_of_week` 필드의 유니크한 값들을 보여준다.
- 물론 이 과정에서 유니크한 필드 개수도 확인할 수 있다.
- 필드 내부의 유니크한 값을 표현해주면서 유니크한 각 값의 도큐먼트 개수도 보여준다.
- `doc_count`는 각각의 유니크한 필드를 가진 도큐먼트 개수다.
- 용어 집계를 이용하면 필드의 유니크한 데이터 개수와 데이터 종류를 확인할 수 있다.


### 검색 결과 내에서의 집계

- 가령 `day_of_week`가 `Monday`인 도큐먼트만으로 메트릭 집계를 수행한다고 가정.
- 이때, 집계 작업을 하기 전에 특정 도큐먼트만 선별 후 그 결과를 토대로 집계 작업을 수행해야할 것이다.

> 쿼리를 이용해 집계 범위 지정

```json
GET kibana_sample_data_ecommerce/_search
{
  "size": 0,
  "query": {
    "term": {
      "day_of_week": {
        "value": "Monday"
      }
    }
  },
  "aggs": {
    "query_aggs": {
      "sum": {
        "field": "products.base_price"
      }
    }
  }
}
```
- **집계를 하기 전에 쿼리를 통해 도큐먼트 범위를 제한했다.**
- 용어 수준 쿼리인 용어 쿼리를 이용해 `day_of_week` 필드 값이 Monday인 도큐먼트만을 일차적으로 골라내고, 이 도큐먼트만을 가지고 query_aggs라는 이름으로 products.base_price 필드의 합을 집계한다.

결과는 다음과 같다.
![](/images/2022-04-11-23-33-34.png)

- 월요일 대상인 579개 도큐먼트에서만 집계를 한다.
- 범위를 제한하는 쿼리가 없으면 인덱스 내 모든 도큐먼트인 4675개에서 집계를 하고, 원하는 결과도 얻지 못할 것이다.