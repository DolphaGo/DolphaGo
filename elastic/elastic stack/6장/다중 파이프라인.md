- [다중 파이프라인](#다중-파이프라인)
  - [다중 파이프라인 작성](#다중-파이프라인-작성)

---

# 다중 파이프라인

- 프로젝트를 진행하다보면, 로그를 입수하는 경로가 다양해진다.
- A라는 서버와 B라는 서버에서 로그를 입수해 하나의 엘라스틱서치에 저장하는 경우가 있을 수 있다.
- 혹은, 하나의 서버에서도 로그 형태가 다른 경우가 있는데 A 프로그램과 B 프로그램 로그를 하나의 엘라스틱서치에 저장하는 경우가 대표적일 것이다.
- 비츠와 카프카에서 나오는 로그를 엘라스틱서치에 함께 저장하려고 하는데, 그 과정에서 로그스태시를 이용해 문자열 구문 분석을 진행하려고 한다.
- 이는 각각 파이프라인 형태가 다른 경우다.
- 비츠에서 나오는 로그/카프카에서 나오는 로그를 모두 동일한 엘라스틱서치에 저장하고 그 안에서 분석해야한다고 해보자.
  - 기존엔 로그스태시를 여러개 실행했다.
    - 그런데 실행된 로그스태시는 개별적이고, 독립적인 JVM 인스턴스라서 모니터링이 어렵고 전체적인 관리가 어려워서 좋은 방법이 아니다.
  - 다른 방법은 로그스태시에 조건문을 두어 분리하는 것
    - 이렇게 하면 하나의 파이프라인으로 처리할 수 있긴 하지만, 필터 처리가 복잡해진다.
    - if ~ else if ~ else if ~ 와 같이 파이프라인이 엄청 지저분해질 것임
  - **결론 : 둘 다 별로임, 다중 파이프라인을 사용하자**


## 다중 파이프라인 작성

![](/images/2022-04-17-20-10-22.png)
 - 다중 파이프라인은 하나의 로그스태시에서 여러 개의 파이프라인을 독립적으로 실행할 수 있게 한다.
 - 다중 파이프라인을 실행하려면, 먼저 **pipelines.yml 파일을 수정해야 한다**
 - pipelines.yml은 config 폴더 내에 있다.
![](/images/2022-04-17-22-09-22.png)

> 파이프라인 설정

| 설정                  | 설명                                                                                                                                                                                                                                                                                                                    |
| --------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `pipeline.id`         | 파이프라인의 고유 아이디                                                                                                                                                                                                                                                                                                |
| `path.config`         | 파이프라인 설정 파일의 위치                                                                                                                                                                                                                                                                                             |
| `pipeline.workers`    | 필터와 출력을 병렬로 처리하기 위한 워커 수, 기본적으로 호스트의 CPU 코어수와 동일하게 설정된다.                                                                                                                                                                                                                         |
| `pipeline.batch.size` | 입력시 하나의 워커 당 최대 몇개까지의 이벤트를 동시에 처리할지를 결정한다. 배치 처리된 이벤트들은 엘라스틱서치 출력에서 하나의 벌크 요청으로 묶이기 때문에, 이 수치가 클수록 요청 수행 횟수가 줄어들어 인덱싱 성능 개선 효과가 있지만, 그만큼 단일 요청이 커지므로 1000, 2000과 같이 적당해 조절해가며 튜닝을 해야한다. |
| `queue.type`          | 파이프라인에서 사용할 큐의 종류를 정할 수 있다. 기본적으로 memory 타입이 사용되나, persisted 타입을 선택해 이벤트의 유실을 좀 더 최소화 할 수도 있다.                                                                                                                                                                   |



그리고 mypipe1.conf 파이프라인을 만들어보자

> mypipe1.conf

```
input {
  file {
    path => "/Users/user/dev/elasticsearch-7.10.2/logs/elasticsearch.log"
    start_position => "beginning"
    sincedb_path => "/dev/null"
    sincedb_clean_after => 0
  }
}

output {
  stdout { }
}
```
- mypipe1 파이프라인은 elasticsearch.log 를 입력으로 받고, 표준 출력으로 모니터 화면에 결과를 보여준다.
- 엘라스틱서치를 실행한 상태라서 위 로그를 예제 파일로 선택했다.


> mypipe2.conf

```
input {
  file {
    path => "/Users/user/dev/elasticsearch-7.10.2/logs/gc.log"
    start_position => "beginning"
    sincedb_path => "/dev/null"
    sincedb_clean_after => 0
  }
}

output {
  elasticsearch {
    index => "multipipe_pipe2"
  }
}
```

- mypipe2 파이프라인은 입력으로 gc.log를 받고, 출력은 엘라스틱서치에 `multipipe_pipe2`라는 인덱스 이름으로 데이터를 저장한다.


> 로그스태시 실행

- 로그스태시를 실행하면 기본적으로 pipelines.yml에 정의되어 있는 파이프라인을 인식하는데, `-f`, `-e`옵션을 사용해 실행하면 pipelines.yml 대신 사용자가 지정한 파이프라인을 사용하게 된다.
- 지금까지는 `-f` 옵션을 이용하여 우리가 만든 파이프라인을 사용했는데 이번엔 -f 옵션 없이 pipelines.yml에 있는 파이프라인을 사용하게 될 것이다.

```sh
sudo bin/logstash
```

> mypipe1 결과 확인

![](/images/2022-04-17-22-13-49.png)
- elasticsearch.log 를 표준 출력으로 보여주고 있다.


> mypipe2 결과 확인


![](/images/2022-04-17-22-12-30.png)
- 로그스태시 로그를 통해 mypipe2는 엘라스틱서치에 인덱스를 생성하고, 로그를 저장하는 것을 확인할 수 있다.