- [파이프라인](#파이프라인)
    - [입력](#입력)
      - [파일 플러그인](#파일-플러그인)

# 파이프라인

- 파이프라인은 데이터를 입력받아 실시간으로 변경하고 이를 다른 시스템에 전달하는 역할을 하는 로그스태시의 핵심 기능.
- 파이프라인은 입력, 필터, 출력이라는 세가지 구성요소로 이루어진다.
  - 입력과 출력은 필수 구성요소이고, 필터는 옵션이다.

![](/images/2022-04-13-02-29-30.png)

- `입력 -> 필터 -> 출력` 순으로 실행되는 것을 알 수 있다.
- 입력: 소스로부터 데이터를 받아들이는 모듈
- 필터: 입력으로 들어오는 데이터를 원하는 형태로 가공하는 모듈
- 출력: 데이터를 외부로 전달하는 모듈


간단한 예제를 통해 파이프라인 구성하는 방법을 배워보자.
표준 입력(키보드)을 받아서 표준 출력(모니터)에 보여주는 간단한 예제를 다시 한 번 실행해보자.

```sh
➜ bin ./logstash -e "input { stdin { } } output { stdout { } }" --log.level error
```

그리고 `hello world`를 타이핑하면 모니터에 다음과 같이 출력된다.
```sh
hello world
{
       "message" => "hello world",
    "@timestamp" => 2022-04-12T17:31:54.741Z,
      "@version" => "1",
          "host" => "AD01718275.local"
}
```

- 로그스태시는 JSON 형태로 출력하는데, `@version` 이나 `@timestamp` 는 로그스태시가 만든 필드로, 혹시 사용자가 만든 필드와 충돌이 날 것을 대비하여 `@` 기호가 붙어있다.
- message : 데이터, host : 시스템 사용자
  - 여기엔 `@`가 붙지 않았는데, `@`가 붙은건 로그스태시가 생성한 필드, 붙지 않은 필드는 수집을 통해 얻은 정보라고 이해하자.


그러나 작업의 이력관리를 위해 pipelines.yml이나 파이프라인 설정 파일을 만들어 로그스태시를 동작하는 것이 좋다.

> 파이프라인 기본 템플릿
```json
input {
    { 입력 플러그인 }
}

filter {
    { 필터 플러그인 }
}

output {
    { 출력 플러그인 }
}
```

- 파이프라인 구성 요소인 입력, 필터, 출력의 내부에 플러그인을 지정할 수 있다.
- 용도나 형태에 맞춰 이미 만들어진 수많은 플러그인이 있기 때문에 필요한 기능을 지원하는 플로그인을 검색하여 템플릿에 추가하면 된다.

### 입력

- 파이프라인의 가장 앞 부분에 위치
- 소스 원본으로부터 데이터를 입력받는 단계
- 직접 대상에 접근해 읽어들이거나 서버를 열어놓고 받아들이는 형태의 구성도 가능

![](/images/2022-04-13-02-43-53.png)

- 로그스태시는 다양한 형태의 데이터를 인식할 수 있고, 이를 쉽게 처리하기 위해 다양한 입력 플러그인들이 존재한다.
  - 예를 들어 특정 파일은 파일 플러그인을, 실시간 트윗은 트위터 플러그인을 통해 가져올 수 있다.


> 자주 사용하는 입력 플러그인

| 입력 플러그인 | 설명                                                               |
| ------------- | ------------------------------------------------------------------ |
| file          | 리눅스의 tail -f 명령처럼 파일을 스트리밍하며 이벤트를 읽어들인다. |
| syslog        | 네트워크를 통해 전달되는 시스로그를 수신한다.                      |
| kafka         | 카프카의 토픽에서 데이터를 읽어 들인다.                            |
| jdbc          | JDBC 드라이버로 지정한 일정마다 쿼리를 실행해 결과를 읽어들인다.   |



#### 파일 플러그인
- 시스템의 특정 파일을 읽어올 수 있도록 구현된 플러그인
![](/images/2022-04-13-02-47-19.png)

- 로그스태시가 설치된 config 폴더에 `logstash-test.conf`라는 이름으로 설정 파일을 만들어보자.

```json
input {
  file {
    path => "/Users/user/dev/logstash-7.10.0/sample-data/sample.log"
    start_position => "beginning"
  }
}

output {
  stdout { }
}
```

- 필터 플러그인은 사용하지 않았고, 입력으로는 파일(file) 플러그인을, 출력으로는 표준 출력(stdout) 플러그인을 사용했다.
- 파일 플러그인에는 여러 옵션이 있는데, 그 중 path는 읽어 들일 파일 위치를 결정한다.
- sample-data 폴더의 `sample.log` 파일을 읽는 것으로 설정했는데, 파일에 로그가 쌓이면 실시간으로 `sample.log` 파일의 변경을 감지해 읽어들인다.
- `start_position`은 최초 파일을 발견했을 때 파일을 읽을 위치로, 파일의 시작 부분부터 읽어들일지 끝부분부터 새로운 라인만 읽어들일지 정할 수 있다.
- 출력은 표준 출력 플러그인을 사용했기 때문에 입력이 발생하면 모니터에 출력한다.
- 꼭 확장자가 `.conf` 일 필요는 없다.
- 파이프라인 설정 파일도 위치 역시 크게 중요한 것은 아니지만, 가능하면 프로젝트끼리 묶어두는 것이 소스 관리 차원에서 좋다.
- 파일 플러그인에는 여러 옵션이 있는데, 그 중 path는 읽어들일 파일 위치를 결정한다.
- 실시간으로 출력되는 `sample.log`를 수집하기 위해 먼저 엘라스틱 서치를 실행하고, 로그스태시를 실행해보자.

우선 sample.log는 다음과 같이 만들어놨다. (참고로 경로도 같이 남겨놓는다.)
```sh
➜ logstash-7.10.0 pwd
/Users/user/dev/logstash-7.10.0

➜ logstash-7.10.0 cat sample-data/sample.log
hihihi
kakakakakakak
DolphaGo
logstash
test
kkk
```

- 실행하기
```sh
➜ logstash-7.10.0 ./bin/logstash -f config/logstash-test.conf
Using bundled JDK: /Users/user/dev/logstash-7.10.0/jdk.app/Contents/Home
OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.jruby.ext.openssl.SecurityHelper (file:/var/folders/tj/79c49zt164l095cfzt3s55qm0000gn/T/jruby-71839/jruby15785364063852713325jopenssl.jar) to field java.security.MessageDigest.provider
WARNING: Please consider reporting this to the maintainers of org.jruby.ext.openssl.SecurityHelper
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
Sending Logstash logs to /Users/user/dev/logstash-7.10.0/logs which is now configured via log4j2.properties
[2022-04-14T01:48:00,425][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"7.10.0", "jruby.version"=>"jruby 9.2.13.0 (2.5.7) 2020-08-03 9a89c94bcc OpenJDK 64-Bit Server VM 11.0.8+10 on 11.0.8+10 +indy +jit [darwin-x86_64]"}
[2022-04-14T01:48:00,598][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2022-04-14T01:48:01,548][INFO ][org.reflections.Reflections] Reflections took 29 ms to scan 1 urls, producing 23 keys and 47 values
[2022-04-14T01:48:01,999][INFO ][logstash.javapipeline    ][main] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>12, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50, "pipeline.max_inflight"=>1500, "pipeline.sources"=>["/Users/user/dev/logstash-7.10.0/config/logstash-test.conf"], :thread=>"#<Thread:0x5a72350 run>"}
[2022-04-14T01:48:02,606][INFO ][logstash.javapipeline    ][main] Pipeline Java execution initialization time {"seconds"=>0.6}
[2022-04-14T01:48:02,758][INFO ][logstash.inputs.file     ][main] No sincedb_path set, generating one based on the "path" setting {:sincedb_path=>"/Users/user/dev/logstash-7.10.0/data/plugins/inputs/file/.sincedb_a68dcadeeda68d177f1758b283c53e5d", :path=>["/Users/user/dev/logstash-7.10.0/sample-data/sample.log"]}
[2022-04-14T01:48:02,773][INFO ][logstash.javapipeline    ][main] Pipeline started {"pipeline.id"=>"main"}
[2022-04-14T01:48:02,799][INFO ][filewatch.observingtail  ][main][41dac5cc54015b8ab9ec2129e5c833c351b87098ebf92f3ee5f9a256ed3ae067] START, creating Discoverer, Watch with file and sincedb collections
[2022-04-14T01:48:02,810][INFO ][logstash.agent           ] Pipelines running {:count=>1, :running_pipelines=>[:main], :non_running_pipelines=>[]}
[2022-04-14T01:48:02,973][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
{
       "message" => "kakakakakakak",
    "@timestamp" => 2022-04-13T16:48:03.019Z,
          "host" => "AD01718275.local",
      "@version" => "1",
          "path" => "/Users/user/dev/logstash-7.10.0/sample-data/sample.log"
}
{
       "message" => "test",
    "@timestamp" => 2022-04-13T16:48:03.021Z,
          "host" => "AD01718275.local",
      "@version" => "1",
          "path" => "/Users/user/dev/logstash-7.10.0/sample-data/sample.log"
}
{
       "message" => "hihihi",
    "@timestamp" => 2022-04-13T16:48:02.997Z,
          "host" => "AD01718275.local",
      "@version" => "1",
          "path" => "/Users/user/dev/logstash-7.10.0/sample-data/sample.log"
}
{
       "message" => "kkk",
    "@timestamp" => 2022-04-13T16:48:03.021Z,
          "host" => "AD01718275.local",
      "@version" => "1",
          "path" => "/Users/user/dev/logstash-7.10.0/sample-data/sample.log"
}
{
       "message" => "DolphaGo",
    "@timestamp" => 2022-04-13T16:48:03.020Z,
          "host" => "AD01718275.local",
      "@version" => "1",
          "path" => "/Users/user/dev/logstash-7.10.0/sample-data/sample.log"
}
{
       "message" => "logstash",
    "@timestamp" => 2022-04-13T16:48:03.020Z,
          "host" => "AD01718275.local",
      "@version" => "1",
          "path" => "/Users/user/dev/logstash-7.10.0/sample-data/sample.log"
}
```

- 내가 만약에, sample.log에 "Hi, I am DolphaGo" 라는 텍스트를 실시간으로 추가하면 어떻게 될까?
- 실시간으로 변경을 감지했기 때문에 다음과 같다.

```json
{
       "message" => "kakakakakakak",
    "@timestamp" => 2022-04-13T16:48:03.019Z,
          "host" => "AD01718275.local",
      "@version" => "1",
          "path" => "/Users/user/dev/logstash-7.10.0/sample-data/sample.log"
}
{
       "message" => "test",
    "@timestamp" => 2022-04-13T16:48:03.021Z,
          "host" => "AD01718275.local",
      "@version" => "1",
          "path" => "/Users/user/dev/logstash-7.10.0/sample-data/sample.log"
}
{
       "message" => "hihihi",
    "@timestamp" => 2022-04-13T16:48:02.997Z,
          "host" => "AD01718275.local",
      "@version" => "1",
          "path" => "/Users/user/dev/logstash-7.10.0/sample-data/sample.log"
}
{
       "message" => "kkk",
    "@timestamp" => 2022-04-13T16:48:03.021Z,
          "host" => "AD01718275.local",
      "@version" => "1",
          "path" => "/Users/user/dev/logstash-7.10.0/sample-data/sample.log"
}
{
       "message" => "DolphaGo",
    "@timestamp" => 2022-04-13T16:48:03.020Z,
          "host" => "AD01718275.local",
      "@version" => "1",
          "path" => "/Users/user/dev/logstash-7.10.0/sample-data/sample.log"
}
{
       "message" => "logstash",
    "@timestamp" => 2022-04-13T16:48:03.020Z,
          "host" => "AD01718275.local",
      "@version" => "1",
          "path" => "/Users/user/dev/logstash-7.10.0/sample-data/sample.log"
}
{
       "message" => "kakakakakakak",
    "@timestamp" => 2022-04-13T16:52:21.906Z,
          "host" => "AD01718275.local",
      "@version" => "1",
          "path" => "/Users/user/dev/logstash-7.10.0/sample-data/sample.log"
}
{
       "message" => "test",
    "@timestamp" => 2022-04-13T16:52:21.906Z,
          "host" => "AD01718275.local",
      "@version" => "1",
          "path" => "/Users/user/dev/logstash-7.10.0/sample-data/sample.log"
}
{
       "message" => "kkk",
    "@timestamp" => 2022-04-13T16:52:21.906Z,
          "host" => "AD01718275.local",
      "@version" => "1",
          "path" => "/Users/user/dev/logstash-7.10.0/sample-data/sample.log"
}
{
       "message" => "Hi, I am DolphaGo",
    "@timestamp" => 2022-04-13T16:52:21.906Z,
          "host" => "AD01718275.local",
      "@version" => "1",
          "path" => "/Users/user/dev/logstash-7.10.0/sample-data/sample.log"
}
{
       "message" => "hihihi",
    "@timestamp" => 2022-04-13T16:52:21.904Z,
          "host" => "AD01718275.local",
      "@version" => "1",
          "path" => "/Users/user/dev/logstash-7.10.0/sample-data/sample.log"
}
{
       "message" => "DolphaGo",
    "@timestamp" => 2022-04-13T16:52:21.906Z,
          "host" => "AD01718275.local",
      "@version" => "1",
          "path" => "/Users/user/dev/logstash-7.10.0/sample-data/sample.log"
}
{
       "message" => "logstash",
    "@timestamp" => 2022-04-13T16:52:21.906Z,
          "host" => "AD01718275.local",
      "@version" => "1",
          "path" => "/Users/user/dev/logstash-7.10.0/sample-data/sample.log"
}
```
- 내가 방금 추가한 `"Hi, I am DolphaGo"` 가 출력되는 것을 확인할 수 있다.
- 그러나, `start_position`을 `beginning`으로 지정했기 때문에 파일을 처음부터 다시 읽어 들이는 것을 확인할 수 있다.
  - 최초 파일을 발견했을 때 파일을 읽을 위치로, 파일의 시작 부분부터 읽어들일지 끝부분부터 새로운 라인만 읽어들일지 정할 수 있었다고 했다.
- 그래서 나머지 `DolphaGo`, `test`, `hihihi` 같은 구문이 2번 반복되었음도 확인할 수 있다.
