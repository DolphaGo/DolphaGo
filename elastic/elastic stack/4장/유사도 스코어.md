# 유사도 스코어

- 쿼리 컨텍스트는 엘라스틱에서 지원하는 다양한 알고리즘을 사용할 수 있는데, 기본적으로 **BM25 알고리즘**을 이용해 유사도 스코어를 계산한다.

- 유사도 스코어는 **질의문과 도큐먼트의 유사도를 표현하는 값**으로, **스코어가 높을 수록 찾고자하는 도큐먼트에 가깝다**는 사실을 의미한다.

- 쿼리를 요청하고, 스코어가 어떤식으로 계산되었는지 알아보기 위해 쿼리에 `explain`옵션을 추가해서 실습해보자.

> 설명이 포함된 쿼리 컨텍스트 실행

```json
GET kibana_sample_data_ecommerce/_search
{
  "query": {
    "match": {
      "products.product_name": "Pants"
    }
  },
  "explain": true
}
```
- 검색 시 위와 같이 `explain: true`를 추가하면 쿼리 내부적인 최적화 방법과 어떤 경로를 통해 검색되었으며, 어떤 기준으로 스코어가 계산되었는지 알 수 있다.
![](/images/2022-04-04-02-18-19.png)

## 스코어 알고리즘(BM25) 이해하기

- 쿼리 컨텍스트로 요청한 응답값을 보면, Hits된 도큐먼트는 모두 스코어(_score) 값을 갖고 있다.
- **스코어란, 도큐먼트와 쿼리 간의 연관성 수치** -> 값이 클수록 연관성이 높다.
- 이 스코어를 계산하기 위해 사용하는 알고리즘이 BM25 알고리즘.
- 엘라스틱 서치가 5.x 부터 BM25알고리즘을 기본으로 사용한다.
- BM25 알고리즘은 검색, 추천에 많이 사용되는 알고리즘으로 TF(Term Frequency), IDF(Inverse Document Frequency) 개 념에 **문서 길이를 고려한 알고리즘**이다.
- **검색어가 문서에 얼마나 자주 나타나는지, 검색어가 문서 내에서 중요한 용어인지 등을 판단하는 근거를 제공**한다.
- (엘라스틱서치의 검색 근간이 되는 루씬이 기본 스코어 알고리즘을 BM25로 바꾸면서 루씬을 코어로 사용하는 엘라스틱서치도 기본 알고리즘을 BM25로 변경하게 되었다.)
- 스코어는 IDF와 TF값을 알면 구할 수 있다.

### IDF 계산

- DF(Document Frequency)는 특정 용어가 얼마나 자주 등장했는지 의미하는 지표
- 문서 빈도가 왜 중요한가?
  - 일반적으로 자주 등장하는 용어는 중요하지 않을 가능성이 높다.
  - `to`, `the` 같은 관사나, `그리고`, `그러나` 같이 문장을 이어주는 접속 부사는 도큐먼트에 자주 나타나는데, 이런 흔한 용어는 사실 큰 의미가 없다.
- 그래서 도큐먼트 내에서 발생 빈도가 적을수록 가중치를 높게 주는데, 이를 **문서 빈도의 역수(Inverse Document Frequency, IDF)** 라고 한다.
- 전체 문서에서 자주 발생하는 단어일수록 중요하지 않은 단어로 인식하고, 가중치를 낮추는 것이다.
- IDF를 계산하는 식은 다음과 같다. (쿼리 explain을 보면 알 수 있다.)
  - `idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:,`
- 변수 N, n 값만 알면 IDF를 구할 수 있다.
  - 변수에 대한 설명과 값도 explain 결과에서 자세히 알려주고 있다.
![](/images/2022-04-04-02-26-58.png)
  - n : 검색했던 용어(term)가 몇 개의 도큐먼트에 있는지를 알려주는 값이다.
    - 총 3개의 도큐먼트에서 products.product_name 필드에 `Pants`라는 용어를 포함하고 있다.
  - N: 인덱스의 전체 도큐먼트 수
    - 즉, kibana_sample_data_ecommerce 인덱스는 총 4657개의 도큐먼트를 갖고 있다.


### TF 계산
- 용어 빈도(Term Frequency, TF)는 특정 용어가 하나의 도큐먼트에 얼마나 많이 등장했는지를 의미하는 지표
- 특정 용어가 도큐먼트에서 많이 반복됐다면, 그 용어는 도큐먼트의 주제와 연관되어 있을 확률이 높다.
- **하나의 도큐먼트에서 특정 용어가 많이 나오면 중요한 용어로 인식하고 가중치를 높인다.**
- TF 계산 식 역시 explain query에서 확인할 수 있다.
  - `tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:`
- 변수 freq, k1, b, dl, avgdl 값을 알면 TF 값을 구할 수 있다.
![](/images/2022-04-04-02-31-13.png)

- freq: 도큐먼트 내에서 용어가 나온 횟수
  - Pants 라는 용어는 이 도큐먼트에서는 한 번 나온 것이다.
- k1, b : 알고리즘을 정규화하기 위한 가중치, 엘라스틱 서치가 디폴트로 취하는 상수
- dl: 필드 길이
- avgdl: 전체 도큐먼트에서 평균 필드 길이
- dl이 작고 avgdl이 클수록 TF 값이 크게 나온다.
  - 이는, 짧은 글에서 찾고자 하는 용어가 포함될 수록 가중치가 높다는 뜻이다.
  - 예를 들어, 짧은 한 문장의 도큐먼트에서 `엘라스틱`이라는 용어가 한 번 들어간 것과 책 한권 분량의 도큐먼트에서 `엘라스틱`이라는 용어가 한 번 들어간 것이 있다면, 당연히 첫 번째 도큐먼트가 `엘라스틱`과 관련있는 도큐먼트일 확률이 높다.
![](/images/2022-04-04-02-42-17.png)
- 위는 `Pants`로 검색햇을 때 스코어가 가장 높았던 도큐먼트다.
- dl: 현재 도큐먼트를 토큰화했을 때의 토큰 수
- avgdl: 인덱스 내의 모든 도큐먼트를 토큰화했을 때의 도큐먼트 당 갖는 평균 토큰 수
- 기본 분석기(standard)를 사용했다면 이 도큐먼트는 [Boots, tan, Casual, Cuffed, Pants] 로 나뉜다. => dl은 5가 된다.
- avgdl은 인덱스 내의 모든 도큐먼트(4675개)의 평균 토큰 수다.
  - 이것 역시 같은 방법으로 토큰화하고 토큰 수를 전체 평균 하면 된다.
  - 그게 7.3이라는 것
- 즉, 현재 이 대상은 다른 도큐먼트에 비해 길이가 짧으면서 검색어를 포함하고 있기 때문에 스코어 수치상 좋은 점수를 받은 것이다.


### 최종 스코어 계산
```json
"value" : 8.268259,
"description" : "score(freq=1.0), computed as boost * idf * tf from:",
"details" : [
{
    "value" : 2.2,
    "description" : "boost",
    "details" : [ ]
}
```

- 최종 스코어는 앞서 배운 IDF와 TF 그리고 boost 변수를 곱하면 된다.
- boost 변수는 엘라스틱이 지정한 고정 값으로 2.2로 정해져 있다.