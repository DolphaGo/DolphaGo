# 유사도 스코어

- 쿼리 컨텍스트는 엘라스틱에서 지원하는 다양한 알고리즘을 사용할 수 있는데, 기본적으로 **BM25 알고리즘**을 이용해 유사도 스코어를 계산한다.

- 유사도 스코어는 **질의문과 도큐먼트의 유사도를 표현하는 값**으로, **스코어가 높을 수록 찾고자하는 도큐먼트에 가깝다**는 사실을 의미한다.

- 쿼리를 요청하고, 스코어가 어떤식으로 계산되었는지 알아보기 위해 쿼리에 `explain`옵션을 추가해서 실습해보자.

> 설명이 포함된 쿼리 컨텍스트 실행

```json
GET kibana_sample_data_ecommerce/_search
{
  "query": {
    "match": {
      "products.product_name": "Pants"
    }
  },
  "explain": true
}
```
- 검색 시 위와 같이 `explain: true`를 추가하면 쿼리 내부적인 최적화 방법과 어떤 경로를 통해 검색되었으며, 어떤 기준으로 스코어가 계산되었는지 알 수 있다.
![](/images/2022-04-04-02-18-19.png)

## 스코어 알고리즘(BM25) 이해하기

- 쿼리 컨텍스트로 요청한 응답값을 보면, Hits된 도큐먼트는 모두 스코어(_score) 값을 갖고 있다.
- **스코어란, 도큐먼트와 쿼리 간의 연관성 수치** -> 값이 클수록 연관성이 높다.
- 이 스코어를 계산하기 위해 사용하는 알고리즘이 BM25 알고리즘.
- 엘라스틱 서치가 5.x 부터 BM25알고리즘을 기본으로 사용한다.
- BM25 알고리즘은 검색, 추천에 많이 사용되는 알고리즘으로 TF(Term Frequency), IDF(Inverse Document Frequency) 개 념에 **문서 길이를 고려한 알고리즘**이다.
- **검색어가 문서에 얼마나 자주 나타나는지, 검색어가 문서 내에서 중요한 용어인지 등을 판단하는 근거를 제공**한다.
- (엘라스틱서치의 검색 근간이 되는 루씬이 기본 스코어 알고리즘을 BM25로 바꾸면서 루씬을 코어로 사용하는 엘라스틱서치도 기본 알고리즘을 BM25로 변경하게 되었다.)
- 스코어는 IDF와 TF값을 알면 구할 수 있다.

### IDF 계산

- DF(Document Frequency)는 특정 용어가 얼마나 자주 등장했는지 의미하는 지표
- 문서 빈도가 왜 중요한가?
  - 일반적으로 자주 등장하는 용어는 중요하지 않을 가능성이 높다.
  - `to`, `the` 같은 관사나, `그리고`, `그러나` 같이 문장을 이어주는 접속 부사는 도큐먼트에 자주 나타나는데, 이런 흔한 용어는 사실 큰 의미가 없다.
- 그래서 도큐먼트 내에서 발생 빈도가 적을수록 가중치를 높게 주는데, 이를 **문서 빈도의 역수(Inverse Document Frequency, IDF)** 라고 한다.
- 전체 문서에서 자주 발생하는 단어일수록 중요하지 않은 단어로 인식하고, 가중치를 낮추는 것이다.
- IDF를 계산하는 식은 다음과 같다. (쿼리 explain을 보면 알 수 있다.)
  - `idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:,`
- 변수 N, n 값만 알면 IDF를 구할 수 있다.
  - 변수에 대한 설명과 값도 explain 결과에서 자세히 알려주고 있다.
![](/images/2022-04-04-02-26-58.png)
  - n : 검색했던 용어(term)가 몇 개의 도큐먼트에 있는지를 알려주는 값이다.
    - 총 3개의 도큐먼트에서 products.product_name 필드에 `Pants`라는 용어를 포함하고 있다.
  - N: 인덱스의 전체 도큐먼트 수
    - 즉, kibana_sample_data_ecommerce 인덱스는 총 4657개의 도큐먼트를 갖고 있다.


### TF 계산
- 용어 빈도(Term Frequency, TF)는 특정 용어가 하나의 도큐먼트에 얼마나 많이 등장했는지를 의미하는 지표
- 특정 용어가 도큐먼트에서 많이 반복됐다면, 그 용어는 도큐먼트의 주제와 연관되어 있을 확률이 높다.
- **하나의 도큐먼트에서 특정 용어가 많이 나오면 중요한 용어로 인식하고 가중치를 높인다.**
- TF 계산 식 역시 explain query에서 확인할 수 있다.
  - `tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:`
- 변수 freq, k1, b, dl, avgdl 값을 알면 TF 값을 구할 수 있다.
![](/images/2022-04-04-02-31-13.png)

- freq: 도큐먼트 내에서 용어가 나온 횟수
  - Pants 라는 용어는 이 도큐먼트에서는 한 번 나온 것이다.
- k1, b : 알고리즘을 정규화하기 위한 가중치, 엘라스틱 서치가 디폴트로 취하는 상수
- dl: 필드 길이
- avgdl: 전체 도큐먼트에서 평균 필드 길이
- dl이 작고 avgdl이 클수록 TF 값이 크게 나온다.
  - 이는, 짧은 글에서 찾고자 하는 용어가 포함될 수록 가중치가 높다는 뜻이다.
  - 예를 들어, 짧은 한 문장의 도큐먼트에서 `엘라스틱`이라는 용어가 한 번 들어간 것과 책 한권 분량의 도큐먼트에서 `엘라스틱`이라는 용어가 한 번 들어간 것이 있다면, 당연히 첫 번째 도큐먼트가 `엘라스틱`과 관련있는 도큐먼트일 확률이 높다.
![](/images/2022-04-04-02-42-17.png)
- 위는 `Pants`로 검색햇을 때 스코어가 가장 높았던 도큐먼트다.
- dl: 현재 도큐먼트를 토큰화했을 때의 토큰 수
- avgdl: 인덱스 내의 모든 도큐먼트를 토큰화했을 때의 도큐먼트 당 갖는 평균 토큰 수
- 기본 분석기(standard)를 사용했다면 이 도큐먼트는 [Boots, tan, Casual, Cuffed, Pants] 로 나뉜다. => dl은 5가 된다.
- avgdl은 인덱스 내의 모든 도큐먼트(4675개)의 평균 토큰 수다.
  - 이것 역시 같은 방법으로 토큰화하고 토큰 수를 전체 평균 하면 된다.
  - 그게 7.3이라는 것
- 즉, 현재 이 대상은 다른 도큐먼트에 비해 길이가 짧으면서 검색어를 포함하고 있기 때문에 스코어 수치상 좋은 점수를 받은 것이다.


### 최종 스코어 계산
```json
"value" : 8.268259,
"description" : "score(freq=1.0), computed as boost * idf * tf from:",
"details" : [
{
    "value" : 2.2,
    "description" : "boost",
    "details" : [ ]
}
```

- 최종 스코어는 앞서 배운 IDF와 TF 그리고 boost 변수를 곱하면 된다.
- boost 변수는 엘라스틱이 지정한 고정 값으로 2.2로 정해져 있다.


> 사내 스터디 중, 팀원분께서 이 내용을 쉽게 설명해주셨다.

유사도 스코어는 검색에서 스코어링의 발전의 순서대로 생각해보면 이해하기 쉽습니다.
TF-IDF까지만 설명하겠습니다.



제일 간단한 개념인 TF는 문서내에 term의 출현빈도에 대한 내용입니다.
찾고싶은 단어를 많이 포함한 문서일 경우, 더 점수를 높게주겠다는 뜻이지요.



예를들면 "나이키 신발"가 쿼리라면,
"나이키", "신발"이 자주 등장한 문서(나이키사이트??)를 더 높은 점수를 주겠지요.

하지만 TF만 사용할 경우에는 예상되는 문제점이 있죠?
"the"나 "이", "그", "저" term들은 특별한 의미가 없음에도 불구하고 자주사용된다는 이유만으로
높은 점수를 받게됩니다. 이는 만족스럽지 않은 검색결과로 나오겠죠.


이를 해결하고자 했던 노력이 idf라고 보시면 됩니다.
수식을 보기전에, term이 출현한 문서에 대해 잠깐 생각해보면 좋겠습니다.
term이 출현한 문서가 많으면 좋을까요? 적으면 좋을까요?
문서가 많다면, 여기저기서 자주쓰이는 term이라 중요하지않다고 볼 수 있고
문서가 적다면, term이 중요하게 사용된다고 볼 수 있습니다.

(term이 출현한 문서 수 / 전체 문서수)로 normalization을 할 수 있지만 여전히 linear한 값이 나옵니다.
여기서 log를 사용한다면 어떻게 될까요?
처음에는 값이 증가하지만, 어느구간에 도달하면 증가세가 감소합니다.
TF의 부작용을 줄일 수 있겠죠?


하지만 아직 큰 문제가 남았습니다.
분수의 값이 1보다 작기때문에 log를 사용하면 음수값이 나오게됩니다.
이거는 사용하려고했던 의도와는 다르죠.
방법이 무엇이 있을까요? x축으로 대칭시키는거죠.

term이 출현한 문서가 많아지면 점수가 적어지고,
term이 출현한 문서가 적어지면 점수가 높아지게됩니다.


수식으로 보면
-log(term이 출현한 문서 수 / 전체 문서수) = log(전체문서수 / term이 출현한 문서수)가 됩니다.
인터넷에서 봤던 idf = log(전체문서수 / term이 출현한 문서수) 과 같습니다.

마지막으로 tf와 idf를 함께 볼까요?
중요한 단어의 출현빈도가 높을수록 가중치를 주는 개념인 TF
term의 출현한 문서가 많을수록 가중치를 낮추는 개념인 IDF

이 두 개를 곱함으로서 적절한 점수를 줄 수 있습니다.
여기까지가 제가 이해한 TF-IDF였습니다.
